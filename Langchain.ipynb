{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGLb2vLWZMcHP+EHQFZFkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EP111111/Langchain_reflection/blob/main/Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1gyqWhcAH6r"
      },
      "outputs": [],
      "source": [
        "pip install google-cloud-aiplatform langchain pandas datasets google-api-python-client\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ3W21GWAeyd",
        "outputId": "f06ce27a-a484-45ca-e964-0e898dd38058"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "ZEtd7-nDBJ71"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL7AmOgPBR1L",
        "outputId": "04809ed1-adde-4ba3-b82b-ae597db483f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI SDK version: 1.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "PROJECT_ID = \"ics-analysis-dev\"\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ],
      "metadata": {
        "id": "S3djpB_DBddO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=512,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "t12nu69UH5o8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. langchain -prompt template"
      ],
      "metadata": {
        "id": "d9RGMCTh7aVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "def reflection(des,text):\n",
        "  template = \"\"\"Description: {des}\n",
        "\n",
        "  Answer: Based on above pattern description and example cases above, determine if the pattern  is presented in the following text:\n",
        "  “{text_for_evaluation}”\n",
        "\n",
        "  Provide a response comprising a result and an explanation for why the pattern is or is not present in JSON format. The explanation should be around 30 words.\n",
        "\n",
        "  Example output:\n",
        "\n",
        "  {{  \"pattern presented\" : “Yes” or “No”,\n",
        "    “Explanation”: “The explanation goes here”\n",
        "  }}\"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(template=template,input_variables=[\"des\",\"text_for_evaluation\"])\n",
        "  feed=prompt.format(des=des,text_for_evaluation=text)\n",
        "  return llm(feed)"
      ],
      "metadata": {
        "id": "ucyWKo2mITyq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "des=\"\"\"Consider a pattern named \"Outcome experience\" that may or may not be present in some text.\n",
        "\n",
        "The text is provided in response to the following question: “Briefly outline the experience. Make a brief note about whether it was good or bad or in between.”\n",
        "\n",
        "Here is a description of  \"Outcome experience\":\n",
        "“Instead of reflecting on a process, the \"experience\" is an outcome (e.g. I got a bad test result).”\n",
        "\n",
        "Now consider a few cases where the pattern is present. In the following cases, the text is given and then the rationale for why the pattern was identified follows:\n",
        "\n",
        "Case 1:\n",
        "Text: “when doing my aim questions on evolution, I was having trouble finding good questions to ask right away”\n",
        "Rationale: “The student has used the outcome of them having trouble finding good questions to ask right away, which is likely secondary to many possible causes such as cognitive load intolerance, lack of practice with the AIM step or lack of focus. Thus, their reflection is scattered and unfocused. Factors that would suggest NO outcome as experience:\n",
        "Factors that would suggest NO outcome as experience:\n",
        "N/A\n",
        "\n",
        "Case 2:\n",
        "Text: “Briefly outline the experience. Make a brief note about whether it was good or bad or in between.I noticed I didn't finish the Kolb's I started a few days ago”\n",
        "Rationale: “Student’s experience is focused on a result and has not mentioned anything in regards to a process in their experience.\n",
        "\n",
        "Factors that would suggest NO outcome as experience:\n",
        "Section “If you struggled, at what points? Were there any triggers?”, student have expanded on their process to some extent.\n",
        "Factors that ULTIMATELY suggest outcome as experience:\n",
        "Any sections where the student does reflect more, it is limited in its depth – a natural consequence of outcome as experience.\n",
        "”\n",
        "\n",
        "Case 3:\n",
        "Text: “I recently failed a computer science test, am struggling with maths and overall with uni and feel burnt out. Frustrating experience (Try to have this kolbs done in 1 hour)”\n",
        "Rationale: “High indication of outcome as experience. Kolb’s seems to have been used as a way to vent and not as a tool to reflect on processes.\n",
        "Factors that would suggest NO outcome as experience:\n",
        "n/a, the student definitely has an outcome as experience.\n",
        "\n",
        "Factors that ULTIMATELY suggest outcome as experience:\n",
        "See above comments.”\n",
        "\n",
        "Case 4:\n",
        "Text: “I struggled to draw the mind map, the visualisations were messy and the diagram lacked logicalcoherence. This was negative.”\n",
        "Rationale: “The student has used the outcome of them having struggling to draw the mindmap in their reflection, but takes this to mean reflecting on the process of them doing the mindmap. This is only borderline outcome as experience.\n",
        "\n",
        "Factors that would suggest NO outcome as experience:\n",
        "The reflection is metacognitive\n",
        "They focus on the mindmapping process\n",
        "\n",
        "Factors that ULTIMATELY suggest outcome as experience:\n",
        "Their experience could be more explicit in stating that they “did a mindmap” rather than the outcome of poor visualisation etc.\n",
        "”\"\"\"\n",
        "text=\"I struggled to draw the mind map, the visualisations were messy and the diagram lacked logical coherence. This was negative.\"\n"
      ],
      "metadata": {
        "id": "aXu3w6BSEa9F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feedback=reflection(des,text)\n",
        "print(feedback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aagMgb7vIoTy",
        "outputId": "1487fc09-768e-4ac1-e821-23a85ac3ef6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \"pattern presented\" : \"Yes\",\n",
            "   \"Explanation\" : \"The student has used the outcome of them having struggling to draw the mindmap in their reflection, but takes this to mean reflecting on the process of them doing the mindmap. This is only borderline outcome as experience.\" \n",
            "  }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ChatVertexAI with langchain"
      ],
      "metadata": {
        "id": "dXs7YOBbKhQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "sicU5QdJBwpf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_models(des,text):\n",
        "  chat = ChatVertexAI()\n",
        "  template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", des),\n",
        "    (\"human\", \"\"\"Based on above pattern description and example cases above, determine if the pattern  is presented in the following text:\n",
        "  “{text_for_evaluation}”\n",
        "\n",
        "  Provide a response comprising a result and an explanation for why the pattern is or is not present in JSON format. The explanation should be around 30 words.\n",
        "\n",
        "  Example output:\n",
        "\n",
        "  {{  \"pattern presented\" : “Yes” or “No”,\n",
        "    “Explanation”: “The explanation goes here”\n",
        "  }}\"\"\"),\n",
        "    ])\n",
        "\n",
        "\n",
        "  messages = template.format_messages(\n",
        "    text_for_evaluation=text\n",
        "  )\n",
        "  return chat(messages)\n"
      ],
      "metadata": {
        "id": "-blttrq9NXIh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feed1=chat_models(des,text)\n",
        "print(feed1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hMgExpYNe15",
        "outputId": "f89e4df1-7388-4d03-f917-f7ecdf3dab6a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " {\n",
            "  \"pattern presented\": \"Yes\",\n",
            "  \"Explanation\": \"The student has used the outcome of them having struggling to draw the mindmap in their reflection, but takes this to mean reflecting on the process of them doing the mindmap.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eBfm6MYZZ94K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}